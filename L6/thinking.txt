Thinking1  奇异值分解SVD的原理是怎样的，都有哪些应用场景
奇异值分解把任意矩阵分解成P,奇异值矩阵,QT，可以理解成矩阵从一组正交基变换到另一组正交基，奇异值代表在单位正交基上的拉伸强度
小的奇异值部分拉伸舍影响小，所以舍弃部分小的奇异值可以做降维，也可以用一部分奇异值还原矩阵，用原矩阵的近似解补全原矩阵缺失部分

Thinking2  funkSVD, BiasSVD，SVD++算法之间的区别是怎样的
funkSVD是解决SVD处理稀疏矩阵效果不好，选k个特征，将Mm*n矩阵分解成Pm*k和Qk*n矩阵，只关注已有评分的部分，对原矩阵已有评分部分和对应的近似解矩阵部分最小化均方误差解p和q，用p和q补全缺失部分
BiasSVD是对funkSVD改进，用类似baseline的方法，在funkSVD的基础上考虑到用户偏好和商品偏好
SVD++是对BiasSVD改进，加入隐式反馈，在BiasSVD基础上考虑到用户的隐式反馈，损失函数里减去隐式反馈的修正值

Thinking3  矩阵分解算法在推荐系统中有哪些应用场景，存在哪些不足
矩阵补全，预测缺失值评分，SVD降维，矩阵分解只能处理两个特征，无法处理多个特征

Thinking4	  item流行度在推荐系统中有怎样的应用
根据内容的流行程度推荐，将榜单中热度高的内容推荐给用户
解决冷启动问题，对于新用户，采用基于流行度的推荐
对于老用户，可以用高流行度对商品推荐降权影响，挖掘长尾

Thinking5  推荐系统的召回阶段都有哪些策略
1.以内容为索引，热点相关的部分文章，点击最高的，离线打分最高的，点击率动态最高的
2.以用户为索引召回，用户最近看过的和时常，根据长期兴趣分布，所在地，停留最长的内容，最相近的用户
3.以设备为索引，根据地点对应群体，推荐点击率最高的